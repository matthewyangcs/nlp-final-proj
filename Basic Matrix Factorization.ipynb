{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8d309f-6b73-4697-95f4-eb449c2ede62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d4bcbd-9676-4775-aa2f-990f305c3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import swifter\n",
    "import multiprocessing\n",
    "import time\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.formula.api as smf\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd0955-a340-4b06-9c5b-d94ad324e4d1",
   "metadata": {},
   "source": [
    "# Loading Processed Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62734bd0-0272-4a10-9622-7a34a46a0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PROCESSED_FOLDER = './data/processed/'\n",
    "PROCESSED_REVIEWS_FILE = 'processed_reviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41db13ef-f58f-4be8-b789-5f5f94e7c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(os.path.join(PROCESSED_FOLDER, PROCESSED_REVIEWS_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f769cfe-cd8f-4a96-bc0c-569c5dfabd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255938</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>First things first. My \"reviews\" system is exp...</td>\n",
       "      <td>8</td>\n",
       "      <td>[['First', 'things', 'first', '.'], ['My', '``...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259117</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Let me start off by saying that Made in Abyss ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[['Let', 'me', 'start', 'off', 'by', 'saying',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253664</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Art 9/10: It is great, especially the actions ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[['Art', '9/10', ':', 'It', 'is', 'great', ','...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247454</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>As someone who loves Studio Ghibli and its mov...</td>\n",
       "      <td>6</td>\n",
       "      <td>[['As', 'someone', 'who', 'loves', 'Studio', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23791</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>code geass is one of those series that everybo...</td>\n",
       "      <td>10</td>\n",
       "      <td>[['code', 'geass', 'is', 'one', 'of', 'those',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  user_id  item_id  \\\n",
       "0     255938        0        1   \n",
       "1     259117        1        2   \n",
       "2     253664        2        3   \n",
       "3     247454        3        4   \n",
       "4      23791        4        5   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  First things first. My \"reviews\" system is exp...       8   \n",
       "1  Let me start off by saying that Made in Abyss ...      10   \n",
       "2  Art 9/10: It is great, especially the actions ...       7   \n",
       "3  As someone who loves Studio Ghibli and its mov...       6   \n",
       "4  code geass is one of those series that everybo...      10   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [['First', 'things', 'first', '.'], ['My', '``...  \n",
       "1  [['Let', 'me', 'start', 'off', 'by', 'saying',...  \n",
       "2  [['Art', '9/10', ':', 'It', 'is', 'great', ','...  \n",
       "3  [['As', 'someone', 'who', 'loves', 'Studio', '...  \n",
       "4  [['code', 'geass', 'is', 'one', 'of', 'those',...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8dc21-b48d-47c4-92b9-5ecade9e196b",
   "metadata": {},
   "source": [
    "# Converting Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13a2335-8f0b-4ad8-9590-912dc3871c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Convert item_id to 0 indexed\n",
    "if min(reviews['item_id']) != 0:\n",
    "    reviews['item_id'] = reviews['item_id'] - 1\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2066316-854c-4484-88cc-8043d5eb0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Review:\n",
    "    user_id: int\n",
    "    item_id: int\n",
    "    rating: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7786b8c-8d87-4e40-aea0-1d5a7933e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_KEY = 'user_id'\n",
    "ITEM_KEY = 'item_id'\n",
    "RATING_KEY = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03cf6817-3799-4833-85b7-cf46631c16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_reviews = defaultdict(list)\n",
    "for _, row in reviews.iterrows():\n",
    "    user_id, item_id, rating = row[USER_KEY], row[ITEM_KEY], row[RATING_KEY]\n",
    "    user_to_reviews[user_id].append(Review(user_id, item_id, rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b88f7-7d4f-41e1-8961-ac55da336a23",
   "metadata": {},
   "source": [
    "## Creating the score matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af2741bc-2256-4222-85b3-12148559e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# users by items\n",
    "X = np.zeros(shape=(reviews['user_id'].nunique(), reviews['item_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b66889-3914-4661-87c9-4d6bcb04b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in reviews.iterrows():\n",
    "    user_id, item_id, rating = row[USER_KEY], row[ITEM_KEY], row[RATING_KEY]\n",
    "    X[user_id][item_id] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4cbb9-e530-4f74-a040-8e25ff0400be",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f8871e-2a53-4338-a7db-42c251f91baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = copy.deepcopy(X)\n",
    "valid_X = np.zeros(shape=X.shape)\n",
    "test_X = np.zeros(shape=X.shape)\n",
    "\n",
    "for user_id, reviews in user_to_reviews.items():\n",
    "    random.shuffle(reviews)\n",
    "    # Leave one out for valid\n",
    "    valid_review = reviews[0]\n",
    "    train_X[valid_review.user_id][valid_review.item_id] = 0\n",
    "    valid_X[valid_review.user_id][valid_review.item_id] = valid_review.rating\n",
    "    \n",
    "    # Leave one out for test\n",
    "    test_review = reviews[1]\n",
    "    train_X[test_review.user_id][test_review.item_id] = 0\n",
    "    test_X[test_review.user_id][test_review.item_id] = test_review.rating\n",
    "    \n",
    "    # Rest for train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39d1ea0-2053-4428-b586-df8fca47c966",
   "metadata": {},
   "source": [
    "## Vanilla MF (vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b075113-a9f4-4ee3-9d09-743659ddc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(values):\n",
    "    return torch.sum(torch.square(values))\n",
    "\n",
    "class VanillaMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=20, regularization_constant=1e-6, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_factors = nn.Embedding(num_items, embedding_dim)\n",
    "        self.regularization_constant = regularization_constant\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, user: torch.LongTensor, item: torch.LongTensor):\n",
    "        # (users, emb_dim) * (items, emb_dim) = (interactions, emb_dim)\n",
    "        result_tensor = self.user_factors(user) * self.item_factors(item)\n",
    "        user_latent_factors = self.user_factors(user)\n",
    "        item_latent_factors = self.item_factors(item)\n",
    "        pred_rating = user_latent_factors @ item_latent_factors.T\n",
    "        pred_rating = 1 + 9 * torch.sigmoid(pred_rating)\n",
    "        return pred_rating.diagonal()\n",
    "    \n",
    "    def loss(self, pred_rating: torch.LongTensor, rating: torch.LongTensor):\n",
    "        MSE_loss = F.mse_loss(pred_rating, rating) + self.eps\n",
    "        \n",
    "        # L2 Regularization\n",
    "        sum_of_squared_values = l2_regularization(self.user_factors.weight) + l2_regularization(self.item_factors.weight)\n",
    "        l2_penalty = (1/len(rating)) * self.regularization_constant * sum_of_squared_values\n",
    "        \n",
    "        # Total Loss\n",
    "        total_loss = MSE_loss + l2_penalty\n",
    "        return total_loss\n",
    "    \n",
    "    def RMSE_loss(self, pred_rating: torch.LongTensor, rating: torch.LongTensor):\n",
    "        # RMSE\n",
    "        RMSE_loss = torch.sqrt(F.mse_loss(pred_rating, rating) + self.eps)\n",
    "        \n",
    "        # L2 Regularization\n",
    "        sum_of_squared_values = l2_regularization(self.user_factors.weight) + l2_regularization(self.item_factors.weight)\n",
    "        l2_penalty = (1/len(rating)) * self.regularization_constant * sum_of_squared_values\n",
    "        \n",
    "        # Total Loss\n",
    "        total_loss = RMSE_loss + l2_penalty\n",
    "        return total_loss\n",
    "    \n",
    "    def predict_single_interaction(self, user_id: int, item_id: int):\n",
    "        user = torch.LongTensor([user_id])\n",
    "        item = torch.LongTensor([item_id])\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ccfc7c5-88ec-47ad-aced-9f57b6e60bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_MSE_loss(eval_X, model, round_digits=3):\n",
    "    \"\"\"Uses reduction mean\"\"\"\n",
    "    user_ids_list, item_ids_list = eval_X.nonzero()\n",
    "    gt_ratings = torch.FloatTensor([eval_X[user_id, item_id] for user_id, item_id in zip(user_ids_list, item_ids_list)])\n",
    "    curr_users_tensor = torch.LongTensor(user_ids_list)\n",
    "    curr_items_tensor = torch.LongTensor(item_ids_list)\n",
    "    pred_ratings = model.forward(curr_users_tensor, curr_items_tensor)\n",
    "    \n",
    "    return round(F.mse_loss(pred_ratings, gt_ratings).item(), 3)\n",
    "\n",
    "def eval_RMSE_loss(eval_X, model):\n",
    "    \"\"\"Uses reduction mean\"\"\"\n",
    "    user_ids_list, item_ids_list = eval_X.nonzero()\n",
    "    gt_ratings = torch.FloatTensor([eval_X[user_id, item_id] for user_id, item_id in zip(user_ids_list, item_ids_list)])\n",
    "    curr_users_tensor = torch.LongTensor(user_ids_list)\n",
    "    curr_items_tensor = torch.LongTensor(item_ids_list)\n",
    "    pred_ratings = model.forward(curr_users_tensor, curr_items_tensor)\n",
    "    \n",
    "    return round(torch.sqrt(F.mse_loss(pred_ratings, gt_ratings)).item(), 3)\n",
    "\n",
    "def eval_MAE_loss(eval_X, model):\n",
    "    \"\"\"Uses reduction mean\"\"\"\n",
    "    user_ids_list, item_ids_list = eval_X.nonzero()\n",
    "    gt_ratings = torch.FloatTensor([eval_X[user_id, item_id] for user_id, item_id in zip(user_ids_list, item_ids_list)])\n",
    "    curr_users_tensor = torch.LongTensor(user_ids_list)\n",
    "    curr_items_tensor = torch.LongTensor(item_ids_list)\n",
    "    pred_ratings = model.forward(curr_users_tensor, curr_items_tensor)\n",
    "    \n",
    "    return round(F.l1_loss(pred_ratings, gt_ratings).item(), 3)\n",
    "\n",
    "\n",
    "def train_v2(train_X, valid_X, model, optimizer, n_epochs=10, batch_size=5):\n",
    "    \"\"\"Training Function, calculates training and validation loss\"\"\"\n",
    "    \n",
    "    for epoch in (range(1, n_epochs+1)):\n",
    "        users, items = train_X.nonzero()\n",
    "        num_examples = len(users)\n",
    "        permuted_indices = np.random.permutation(num_examples)\n",
    "        users, items = users[permuted_indices], items[permuted_indices]\n",
    "        \n",
    "\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        \n",
    "        for i in tqdm(range(num_examples // batch_size)):\n",
    "            user_ids_list = users[i*batch_size:i*batch_size+batch_size]\n",
    "            item_ids_list = items[i*batch_size:i*batch_size+batch_size]\n",
    "\n",
    "            # Set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Turn data into tensors\n",
    "            rating = torch.FloatTensor([train_X[user_id, item_id] for user_id, item_id in zip(user_ids_list, item_ids_list)])\n",
    "            curr_users_tensor = torch.LongTensor(user_ids_list)\n",
    "            curr_items_tensor = torch.LongTensor(item_ids_list)\n",
    "\n",
    "            # Predict and calculate loss\n",
    "            pred_rating = model.forward(curr_users_tensor, curr_items_tensor)\n",
    "            assert pred_rating.shape == rating.shape\n",
    "            # loss = model.loss(pred_rating, rating)\n",
    "            loss = model.RMSE_loss(pred_rating, rating)\n",
    "\n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # MSE Loss w/o regularization (just for status updates)\n",
    "            total_train_loss += F.mse_loss(pred_rating, rating, reduction='sum')\n",
    "\n",
    "        # Computing validation loss for display\n",
    "        total_valid_loss = eval_MSE_loss(valid_X, model)\n",
    "        total_valid_RMSE_loss = eval_RMSE_loss(valid_X, model)\n",
    "        total_valid_MAE_loss = eval_MAE_loss(valid_X, model)\n",
    "        \n",
    "        print(f\"Epoch {epoch} MSE Loss: {round(total_train_loss.item() / (batch_size * (num_examples//batch_size)), 3)}, valid MSE Loss: {total_valid_loss}, valid RMSE Loss: {total_valid_RMSE_loss}, valid MAE Loss: {total_valid_MAE_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e0d79-d054-4bef-889e-7f88187c0ba2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11c1db45-4126-4bb2-86bb-eb1f3d8102e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameter settings are pretty good, just adjust LR after you get low enough => MSE of 3.6)\n",
    "# batch_size=64\n",
    "# Adam\n",
    "# weight decay in regularization constant\n",
    "embedding_dim=200\n",
    "lr=1e-2\n",
    "regularization_constant=1e-2\n",
    "\n",
    "model = VanillaMF(num_users=X.shape[0], num_items=X.shape[1], embedding_dim=embedding_dim, regularization_constant=regularization_constant)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45594946-1156-49a7-8b16-c44c500b5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v2(train_X, valid_X, model, optimizer, n_epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88634e08-b868-4c34-b0dd-66762819ea5b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "273f1066-9813-4096-b953-2155f3b4ea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE Loss: 25.407, test RMSE Loss: 5.041, test MAE Loss: 4.211\n"
     ]
    }
   ],
   "source": [
    "total_test_loss = eval_MSE_loss(test_X, model)\n",
    "total_test_RMSE_loss = eval_RMSE_loss(test_X, model)\n",
    "total_test_MAE_loss = eval_MAE_loss(test_X, model)\n",
    "print(f\"test MSE Loss: {total_test_loss}, test RMSE Loss: {total_test_RMSE_loss}, test MAE Loss: {total_test_MAE_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc25009-27a2-4cb1-af75-42b40a5cfc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
