{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8d309f-6b73-4697-95f4-eb449c2ede62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "24d4bcbd-9676-4775-aa2f-990f305c3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import swifter\n",
    "import multiprocessing\n",
    "import time\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.formula.api as smf\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd0955-a340-4b06-9c5b-d94ad324e4d1",
   "metadata": {},
   "source": [
    "# Loading Processed Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62734bd0-0272-4a10-9622-7a34a46a0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PROCESSED_FOLDER = './data/processed/'\n",
    "PROCESSED_REVIEWS_FILE = 'processed_reviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41db13ef-f58f-4be8-b789-5f5f94e7c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(os.path.join(PROCESSED_FOLDER, PROCESSED_REVIEWS_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f769cfe-cd8f-4a96-bc0c-569c5dfabd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255938</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>First things first. My \"reviews\" system is exp...</td>\n",
       "      <td>8</td>\n",
       "      <td>[['First', 'things', 'first', '.'], ['My', '``...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259117</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Let me start off by saying that Made in Abyss ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[['Let', 'me', 'start', 'off', 'by', 'saying',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253664</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Art 9/10: It is great, especially the actions ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[['Art', '9/10', ':', 'It', 'is', 'great', ','...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247454</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>As someone who loves Studio Ghibli and its mov...</td>\n",
       "      <td>6</td>\n",
       "      <td>[['As', 'someone', 'who', 'loves', 'Studio', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23791</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>code geass is one of those series that everybo...</td>\n",
       "      <td>10</td>\n",
       "      <td>[['code', 'geass', 'is', 'one', 'of', 'those',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  user_id  item_id  \\\n",
       "0     255938        0        1   \n",
       "1     259117        1        2   \n",
       "2     253664        2        3   \n",
       "3     247454        3        4   \n",
       "4      23791        4        5   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  First things first. My \"reviews\" system is exp...       8   \n",
       "1  Let me start off by saying that Made in Abyss ...      10   \n",
       "2  Art 9/10: It is great, especially the actions ...       7   \n",
       "3  As someone who loves Studio Ghibli and its mov...       6   \n",
       "4  code geass is one of those series that everybo...      10   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [['First', 'things', 'first', '.'], ['My', '``...  \n",
       "1  [['Let', 'me', 'start', 'off', 'by', 'saying',...  \n",
       "2  [['Art', '9/10', ':', 'It', 'is', 'great', ','...  \n",
       "3  [['As', 'someone', 'who', 'loves', 'Studio', '...  \n",
       "4  [['code', 'geass', 'is', 'one', 'of', 'those',...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8dc21-b48d-47c4-92b9-5ecade9e196b",
   "metadata": {},
   "source": [
    "# Converting Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13a2335-8f0b-4ad8-9590-912dc3871c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Convert item_id to 0 indexed\n",
    "if min(reviews['item_id']) != 0:\n",
    "    reviews['item_id'] = reviews['item_id'] - 1\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2066316-854c-4484-88cc-8043d5eb0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Review:\n",
    "    user_id: int\n",
    "    item_id: int\n",
    "    rating: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7786b8c-8d87-4e40-aea0-1d5a7933e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_KEY = 'user_id'\n",
    "ITEM_KEY = 'item_id'\n",
    "RATING_KEY = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03cf6817-3799-4833-85b7-cf46631c16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_reviews = defaultdict(list)\n",
    "for _, row in reviews.iterrows():\n",
    "    user_id, item_id, rating = row[USER_KEY], row[ITEM_KEY], row[RATING_KEY]\n",
    "    user_to_reviews[user_id].append(Review(user_id, item_id, rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aac691-4002-4fbb-89fb-905f46d5c993",
   "metadata": {},
   "source": [
    "## Creating the score matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af2741bc-2256-4222-85b3-12148559e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# users by items\n",
    "X = np.zeros(shape=(reviews['user_id'].nunique(), reviews['item_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b66889-3914-4661-87c9-4d6bcb04b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in reviews.iterrows():\n",
    "    user_id, item_id, rating = row[USER_KEY], row[ITEM_KEY], row[RATING_KEY]\n",
    "    X[user_id][item_id] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79db731-69f2-4051-bdc9-760bf6e93820",
   "metadata": {},
   "source": [
    "# Vanilla Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e1f064-9418-44dd-b065-06c3e93348ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(values):\n",
    "    return torch.sum(torch.square(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc880eb6-c7e8-45e0-aa39-ec6f343482bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=20, regularization_constant=1e-6):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_factors = nn.Embedding(num_items, embedding_dim)\n",
    "        self.regularization_constant = regularization_constant\n",
    "        \n",
    "    def forward(self, user: torch.LongTensor, item: torch.LongTensor):\n",
    "        # (1,20) dot prod with (1,20) gives us (1,20)\n",
    "        # Embedding output tensor has shape (*, n_factors)\n",
    "        result_tensor = self.user_factors(user) * self.item_factors(item)\n",
    "        # Sum along row\n",
    "        pred_rating = torch.sum(result_tensor, axis=1)\n",
    "        return pred_rating\n",
    "    \n",
    "    def loss(self, pred_rating, rating):\n",
    "        # MSE\n",
    "        MSE_loss = F.mse_loss(pred_rating, rating)\n",
    "        \n",
    "        # L2 Regularization\n",
    "        sum_of_squared_values = l2_regularization(self.user_factors.weight) + l2_regularization(self.item_factors.weight)\n",
    "        l2_penalty = self.regularization_constant * sum_of_squared_values\n",
    "        \n",
    "        # Total Loss\n",
    "        total_loss = MSE_loss + l2_penalty\n",
    "        return total_loss\n",
    "    \n",
    "    def predict(self, user_id: int, item_id: int):\n",
    "        user = torch.LongTensor([user_id])\n",
    "        item = torch.LongTensor([item_id])\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b909e-97c9-4b75-bce4-c701a0755117",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1456193-df11-4038-a444-c8a384a3355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_X, valid_X, model, optimizer, n_epochs=10):\n",
    "    \"\"\"Training Function, calculates training and validation loss\"\"\"\n",
    "    \n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        rows, cols = train_X.nonzero()\n",
    "        p = np.random.permutation(len(rows))\n",
    "        rows, cols = rows[p], cols[p]\n",
    "        \n",
    "        # Loss doesn't include regularization term\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for row, col in zip(rows, cols):\n",
    "            # Set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Turn data into tensors\n",
    "            rating = torch.FloatTensor([train_X[row, col]])\n",
    "            row = torch.LongTensor([row])\n",
    "            col = torch.LongTensor([col])\n",
    "\n",
    "            # Predict and calculate loss\n",
    "            pred_rating = model.forward(row, col)\n",
    "            # assert pred_rating.shape == rating.shape\n",
    "            loss = model.loss(pred_rating, rating)\n",
    "            \n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Total MSE Loss (just for status updates) for this epoch\n",
    "            total_train_loss += F.mse_loss(pred_rating, rating)\n",
    "\n",
    "        # Loss doesn't include regularization term\n",
    "        total_valid_loss = 0\n",
    "        rows, cols = valid_X.nonzero()\n",
    "        for row, col in zip(rows, cols):\n",
    "            rating = torch.FloatTensor([valid_X[row, col]])\n",
    "            pred_rating = model.predict(row, col)\n",
    "            total_valid_loss += model.loss(pred_rating, rating)\n",
    "            \n",
    "        \n",
    "        print(f\"Epoch {epoch} MSE Loss: {total_train_loss / len(train_X.nonzero()[0])}\")\n",
    "        print(f\"Epoch {epoch} valid MSE Loss: {total_valid_loss / len(valid_X.nonzero()[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4cbb9-e530-4f74-a040-8e25ff0400be",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52f8871e-2a53-4338-a7db-42c251f91baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = copy.deepcopy(X)\n",
    "valid_X = np.zeros(shape=X.shape)\n",
    "test_X = np.zeros(shape=X.shape)\n",
    "\n",
    "for user_id, reviews in user_to_reviews.items():\n",
    "    random.shuffle(reviews)\n",
    "    # Leave one out for valid\n",
    "    valid_review = reviews[0]\n",
    "    train_X[valid_review.user_id][valid_review.item_id] = 0\n",
    "    valid_X[valid_review.user_id][valid_review.item_id] = valid_review.rating\n",
    "    \n",
    "    # Leave one out for test\n",
    "    test_review = reviews[1]\n",
    "    train_X[test_review.user_id][test_review.item_id] = 0\n",
    "    test_X[test_review.user_id][test_review.item_id] = test_review.rating\n",
    "    \n",
    "    # Rest for train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b8dc5-071e-4f3f-8918-9d96a1e84748",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72860d7b-b5db-48d1-8eaa-a197e72982f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=20\n",
    "lr=1e-2\n",
    "regularization_constant=0\n",
    "\n",
    "model = VanillaMF(num_users=X.shape[0], num_items=X.shape[1], embedding_dim=embedding_dim, regularization_constant=regularization_constant)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ea9f2-bffe-4928-b806-f251a1d93bc6",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98a5abe5-938e-4c34-9e3b-88a2fd8222da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m(train_X, valid_X, model, optimizer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train(train_X, valid_X, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39d1ea0-2053-4428-b586-df8fca47c966",
   "metadata": {},
   "source": [
    "## Vectorized Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ed7ca0b-61a9-48ea-bdf7-90cabba194f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(values):\n",
    "    return torch.sum(torch.square(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8b075113-a9f4-4ee3-9d09-743659ddc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=20, regularization_constant=1e-6):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_factors = nn.Embedding(num_items, embedding_dim)\n",
    "        self.regularization_constant = regularization_constant\n",
    "        \n",
    "    def forward(self, user: torch.LongTensor, item: torch.LongTensor):\n",
    "        # (users, emb_dim) * (items, emb_dim) = (interactions, emb_dim)\n",
    "        result_tensor = self.user_factors(user) * self.item_factors(item)\n",
    "        user_latent_factors = self.user_factors(user)\n",
    "        item_latent_factors = self.item_factors(item)\n",
    "        pred_rating = user_latent_factors @ item_latent_factors.T\n",
    "        # Sum along row\n",
    "        # pred_rating = torch.sum(result_tensor, axis=1)\n",
    "        pred_rating = 10 * torch.sigmoid(pred_rating)\n",
    "        return pred_rating.diagonal()\n",
    "    \n",
    "    def loss(self, pred_rating, rating):\n",
    "        # MSE\n",
    "        MSE_loss = F.mse_loss(pred_rating, rating)\n",
    "        \n",
    "        # L2 Regularization\n",
    "        sum_of_squared_values = l2_regularization(self.user_factors.weight) + l2_regularization(self.item_factors.weight)\n",
    "        l2_penalty = (1/len(rating)) * self.regularization_constant * sum_of_squared_values\n",
    "        \n",
    "        # Total Loss\n",
    "        total_loss = MSE_loss + l2_penalty\n",
    "        return total_loss\n",
    "    \n",
    "    def predict_single_interaction(self, user_id: int, item_id: int):\n",
    "        user = torch.LongTensor([user_id])\n",
    "        item = torch.LongTensor([item_id])\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "3ccfc7c5-88ec-47ad-aced-9f57b6e60bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_v2(train_X, valid_X, model, optimizer, n_epochs=10, batch_size=5):\n",
    "    \"\"\"Training Function, calculates training and validation loss\"\"\"\n",
    "    \n",
    "    for epoch in (range(1, n_epochs+1)):\n",
    "        rows, cols = train_X.nonzero()\n",
    "        p = np.random.permutation(len(rows))\n",
    "        \n",
    "        \n",
    "        rows, cols = rows[p], cols[p]\n",
    "\n",
    "        \n",
    "        # Loss doesn't include regularization term\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for i in tqdm(range(len(rows) // batch_size)):\n",
    "            curr_rows = rows[i*batch_size:i*batch_size+batch_size]\n",
    "            curr_cols = cols[i*batch_size:i*batch_size+batch_size]\n",
    "\n",
    "            # Set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Turn data into tensors\n",
    "            # rating = torch.FloatTensor([[train_X[row, col] for row,col in zip(curr_rows, curr_cols)])\n",
    "            rating = torch.FloatTensor([train_X[row, col] for row,col in zip(curr_rows, curr_cols)])\n",
    "            users = torch.LongTensor(curr_rows)\n",
    "            items = torch.LongTensor(curr_cols)\n",
    "\n",
    "            # Predict and calculate loss\n",
    "            pred_rating = model.forward(users, items)\n",
    "            assert pred_rating.shape == rating.shape\n",
    "            loss = model.loss(pred_rating, rating)\n",
    "\n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total MSE Loss (just for status updates) for this epoch\n",
    "            total_train_loss += F.mse_loss(pred_rating, rating, reduction='sum')\n",
    "\n",
    "        # Loss doesn't include regularization term\n",
    "        rows, cols = valid_X.nonzero()\n",
    "        rating = torch.FloatTensor([valid_X[row, col] for row, col in zip(rows, cols)])\n",
    "        users = torch.LongTensor(rows)\n",
    "        items = torch.LongTensor(cols)\n",
    "\n",
    "        # Predict and calculate loss\n",
    "        pred_rating = torch.clamp(model.forward(users, items), min=1)\n",
    "        \n",
    "        total_valid_loss = F.mse_loss(pred_rating, rating, reduction='sum')\n",
    "            \n",
    "        \n",
    "        print(f\"Epoch {epoch} MSE Loss: {total_train_loss / len(train_X.nonzero()[0])}, valid MSE Loss: {total_valid_loss / len(valid_X.nonzero()[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2ae56c09-3a28-4e14-9f0f-95791de7c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=40\n",
    "lr=1e-3\n",
    "regularization_constant=0\n",
    "\n",
    "model = VanillaMF(num_users=X.shape[0], num_items=X.shape[1], embedding_dim=embedding_dim, regularization_constant=regularization_constant)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9b64ed02-94eb-4168-abcd-5d9f8a88b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight decay in regularization constant\n",
    "embedding_dim=100\n",
    "lr=1e-3\n",
    "regularization_constant=0\n",
    "\n",
    "model = VanillaMF(num_users=X.shape[0], num_items=X.shape[1], embedding_dim=embedding_dim, regularization_constant=regularization_constant)\n",
    "# optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, momentum=0.9)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "11c1db45-4126-4bb2-86bb-eb1f3d8102e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameter settings are pretty good, just adjust LR after you get low enough => MSE of 3.6)\n",
    "# batch_size=64\n",
    "# Adam\n",
    "# weight decay in regularization constant\n",
    "embedding_dim=200\n",
    "lr=1e-2\n",
    "regularization_constant=1e-2\n",
    "\n",
    "model = VanillaMF(num_users=X.shape[0], num_items=X.shape[1], embedding_dim=embedding_dim, regularization_constant=regularization_constant)\n",
    "# optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "bd0b8676-4715-4300-a9f2-4b58970d01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = copy.deepcopy(X)\n",
    "# valid_X = np.zeros(shape=X.shape)\n",
    "# test_X = np.zeros(shape=X.shape)\n",
    "\n",
    "# for user_id, reviews in user_to_reviews.items():\n",
    "#     random.shuffle(reviews)\n",
    "#     # Leave one out for valid\n",
    "#     valid_review = reviews[0]\n",
    "#     train_X[valid_review.user_id][valid_review.item_id] = 0\n",
    "#     valid_X[valid_review.user_id][valid_review.item_id] = valid_review.rating\n",
    "    \n",
    "#     # Leave one out for test\n",
    "#     test_review = reviews[1]\n",
    "#     train_X[test_review.user_id][test_review.item_id] = 0\n",
    "#     test_X[test_review.user_id][test_review.item_id] = test_review.rating\n",
    "    \n",
    "#     # Rest for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "99ad54cb-f27d-471f-b739-d87876b3e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "model.regularization_constant = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "7a709e25-b2a7-4892-817a-b7f39114eb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 508/508 [00:02<00:00, 205.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4538, grad_fn=<UnbindBackward0>)\n",
      "Epoch 1 MSE Loss: 0.4036567211151123, valid MSE Loss: 3.7022593021392822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 508/508 [00:02<00:00, 223.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5889, grad_fn=<UnbindBackward0>)\n",
      "Epoch 2 MSE Loss: 0.35511884093284607, valid MSE Loss: 3.6945083141326904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 508/508 [00:02<00:00, 225.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3402, grad_fn=<UnbindBackward0>)\n",
      "Epoch 3 MSE Loss: 0.36438891291618347, valid MSE Loss: 3.7024178504943848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 508/508 [00:02<00:00, 225.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6420, grad_fn=<UnbindBackward0>)\n",
      "Epoch 4 MSE Loss: 0.3530783951282501, valid MSE Loss: 3.717691421508789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████▍                 | 260/508 [00:01<00:01, 209.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [346]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [345]\u001b[0m, in \u001b[0;36mtrain_v2\u001b[0;34m(train_X, valid_X, model, optimizer, n_epochs, batch_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss(pred_rating, rating)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Backpropagate\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Update the parameters\u001b[39;00m\n\u001b[1;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlp/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_v2(train_X, valid_X, model, optimizer, n_epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45594946-1156-49a7-8b16-c44c500b5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v2(train_X, valid_X, model, optimizer, n_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "35c477e5-3a8e-4a23-9a11-0257760420df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(58.3486, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows, cols = test_X.nonzero()\n",
    "rating = torch.FloatTensor([test_X[row, col] for row, col in zip(rows, cols)])\n",
    "users = torch.LongTensor(rows)\n",
    "items = torch.LongTensor(cols)\n",
    "\n",
    "# Predict and calculate loss\n",
    "pred_rating = model.forward(users, items)\n",
    "total_valid_loss = F.mse_loss(pred_rating, rating)\n",
    "total_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "40acdc99-1830-4170-b8ec-8f57980f3a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef0818b-eabf-4d70-8b6e-afaec609fed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92be5311-2c6a-41b3-94ca-1ba6d8b160b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = torch.FloatTensor([X[0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c95f6bd-3df3-4d90-b69d-8ccea341500b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c21a8af-51a1-43e0-9213-b1f18e2c3703",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = torch.LongTensor([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d44ef71-c3c3-41d4-bb0b-f5bb341ab74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = torch.LongTensor([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36bb49bd-d13f-49e4-9fe9-6f501b59e73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, tensor([0]), tensor([0]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating, row, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ad01c-b4d6-4be3-9bc0-53552a98e61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
