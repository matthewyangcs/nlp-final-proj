{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8d309f-6b73-4697-95f4-eb449c2ede62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d4bcbd-9676-4775-aa2f-990f305c3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import swifter\n",
    "import multiprocessing\n",
    "import time\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.formula.api as smf\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd0955-a340-4b06-9c5b-d94ad324e4d1",
   "metadata": {},
   "source": [
    "# Loading Processed Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62734bd0-0272-4a10-9622-7a34a46a0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PROCESSED_FOLDER = './data/processed/'\n",
    "# PROCESSED_REVIEWS_FILE = 'processed_reviews.csv'\n",
    "PROCESSED_REVIEWS_FILE = 'processed_reviews_with_sentiment.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41db13ef-f58f-4be8-b789-5f5f94e7c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(os.path.join(PROCESSED_FOLDER, PROCESSED_REVIEWS_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f769cfe-cd8f-4a96-bc0c-569c5dfabd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>neg_sent_avg</th>\n",
       "      <th>neu_sent_avg</th>\n",
       "      <th>pos_sent_avg</th>\n",
       "      <th>compound_sent_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255938</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>First things first. My \"reviews\" system is exp...</td>\n",
       "      <td>8</td>\n",
       "      <td>[['First', 'things', 'first', '.'], ['My', '``...</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.757708</td>\n",
       "      <td>0.168937</td>\n",
       "      <td>0.208675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259117</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Let me start off by saying that Made in Abyss ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[['Let', 'me', 'start', 'off', 'by', 'saying',...</td>\n",
       "      <td>0.062741</td>\n",
       "      <td>0.759333</td>\n",
       "      <td>0.177963</td>\n",
       "      <td>0.302804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253664</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Art 9/10: It is great, especially the actions ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[['Art', '9/10', ':', 'It', 'is', 'great', ','...</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>0.792889</td>\n",
       "      <td>0.159833</td>\n",
       "      <td>0.220767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247454</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>As someone who loves Studio Ghibli and its mov...</td>\n",
       "      <td>6</td>\n",
       "      <td>[['As', 'someone', 'who', 'loves', 'Studio', '...</td>\n",
       "      <td>0.055577</td>\n",
       "      <td>0.809192</td>\n",
       "      <td>0.135269</td>\n",
       "      <td>0.187896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23791</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>code geass is one of those series that everybo...</td>\n",
       "      <td>10</td>\n",
       "      <td>[['code', 'geass', 'is', 'one', 'of', 'those',...</td>\n",
       "      <td>0.028857</td>\n",
       "      <td>0.723000</td>\n",
       "      <td>0.248143</td>\n",
       "      <td>0.534129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  user_id  item_id  \\\n",
       "0     255938        0        1   \n",
       "1     259117        1        2   \n",
       "2     253664        2        3   \n",
       "3     247454        3        4   \n",
       "4      23791        4        5   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  First things first. My \"reviews\" system is exp...       8   \n",
       "1  Let me start off by saying that Made in Abyss ...      10   \n",
       "2  Art 9/10: It is great, especially the actions ...       7   \n",
       "3  As someone who loves Studio Ghibli and its mov...       6   \n",
       "4  code geass is one of those series that everybo...      10   \n",
       "\n",
       "                                      tokenized_text  neg_sent_avg  \\\n",
       "0  [['First', 'things', 'first', '.'], ['My', '``...      0.073333   \n",
       "1  [['Let', 'me', 'start', 'off', 'by', 'saying',...      0.062741   \n",
       "2  [['Art', '9/10', ':', 'It', 'is', 'great', ','...      0.047278   \n",
       "3  [['As', 'someone', 'who', 'loves', 'Studio', '...      0.055577   \n",
       "4  [['code', 'geass', 'is', 'one', 'of', 'those',...      0.028857   \n",
       "\n",
       "   neu_sent_avg  pos_sent_avg  compound_sent_avg  \n",
       "0      0.757708      0.168937           0.208675  \n",
       "1      0.759333      0.177963           0.302804  \n",
       "2      0.792889      0.159833           0.220767  \n",
       "3      0.809192      0.135269           0.187896  \n",
       "4      0.723000      0.248143           0.534129  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8dc21-b48d-47c4-92b9-5ecade9e196b",
   "metadata": {},
   "source": [
    "# Converting Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13a2335-8f0b-4ad8-9590-912dc3871c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Convert item_id to 0 indexed\n",
    "if min(reviews['item_id']) != 0:\n",
    "    reviews['item_id'] = reviews['item_id'] - 1\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2066316-854c-4484-88cc-8043d5eb0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Review:\n",
    "    user_id: int\n",
    "    item_id: int\n",
    "    rating: int\n",
    "    text: str\n",
    "    pos_sent: float\n",
    "    neg_sent: float\n",
    "    compound_sent: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7786b8c-8d87-4e40-aea0-1d5a7933e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_KEY = 'user_id'\n",
    "ITEM_KEY = 'item_id'\n",
    "RATING_KEY = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67804fba-a838-4d53-ab38-dfc529312286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>neg_sent_avg</th>\n",
       "      <th>neu_sent_avg</th>\n",
       "      <th>pos_sent_avg</th>\n",
       "      <th>compound_sent_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>First things first. My \"reviews\" system is exp...</td>\n",
       "      <td>8</td>\n",
       "      <td>[['First', 'things', 'first', '.'], ['My', '``...</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.757708</td>\n",
       "      <td>0.168937</td>\n",
       "      <td>0.208675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259117</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Let me start off by saying that Made in Abyss ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[['Let', 'me', 'start', 'off', 'by', 'saying',...</td>\n",
       "      <td>0.062741</td>\n",
       "      <td>0.759333</td>\n",
       "      <td>0.177963</td>\n",
       "      <td>0.302804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253664</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Art 9/10: It is great, especially the actions ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[['Art', '9/10', ':', 'It', 'is', 'great', ','...</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>0.792889</td>\n",
       "      <td>0.159833</td>\n",
       "      <td>0.220767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247454</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>As someone who loves Studio Ghibli and its mov...</td>\n",
       "      <td>6</td>\n",
       "      <td>[['As', 'someone', 'who', 'loves', 'Studio', '...</td>\n",
       "      <td>0.055577</td>\n",
       "      <td>0.809192</td>\n",
       "      <td>0.135269</td>\n",
       "      <td>0.187896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23791</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>code geass is one of those series that everybo...</td>\n",
       "      <td>10</td>\n",
       "      <td>[['code', 'geass', 'is', 'one', 'of', 'those',...</td>\n",
       "      <td>0.028857</td>\n",
       "      <td>0.723000</td>\n",
       "      <td>0.248143</td>\n",
       "      <td>0.534129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  user_id  item_id  \\\n",
       "0     255938        0        0   \n",
       "1     259117        1        1   \n",
       "2     253664        2        2   \n",
       "3     247454        3        3   \n",
       "4      23791        4        4   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  First things first. My \"reviews\" system is exp...       8   \n",
       "1  Let me start off by saying that Made in Abyss ...      10   \n",
       "2  Art 9/10: It is great, especially the actions ...       7   \n",
       "3  As someone who loves Studio Ghibli and its mov...       6   \n",
       "4  code geass is one of those series that everybo...      10   \n",
       "\n",
       "                                      tokenized_text  neg_sent_avg  \\\n",
       "0  [['First', 'things', 'first', '.'], ['My', '``...      0.073333   \n",
       "1  [['Let', 'me', 'start', 'off', 'by', 'saying',...      0.062741   \n",
       "2  [['Art', '9/10', ':', 'It', 'is', 'great', ','...      0.047278   \n",
       "3  [['As', 'someone', 'who', 'loves', 'Studio', '...      0.055577   \n",
       "4  [['code', 'geass', 'is', 'one', 'of', 'those',...      0.028857   \n",
       "\n",
       "   neu_sent_avg  pos_sent_avg  compound_sent_avg  \n",
       "0      0.757708      0.168937           0.208675  \n",
       "1      0.759333      0.177963           0.302804  \n",
       "2      0.792889      0.159833           0.220767  \n",
       "3      0.809192      0.135269           0.187896  \n",
       "4      0.723000      0.248143           0.534129  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03cf6817-3799-4833-85b7-cf46631c16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_reviews = defaultdict(list)\n",
    "for _, row in reviews.iterrows():\n",
    "    user_id, item_id, rating, text = row[USER_KEY], row[ITEM_KEY], row[RATING_KEY], row['text']\n",
    "    pos_sent, neg_sent, compound_sent = row['pos_sent_avg'], row['neg_sent_avg'], row['compound_sent_avg']\n",
    "    user_to_reviews[user_id].append(Review(user_id, item_id, rating, text, pos_sent, neg_sent, compound_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aac691-4002-4fbb-89fb-905f46d5c993",
   "metadata": {},
   "source": [
    "## Creating the score matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2741bc-2256-4222-85b3-12148559e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# users by items\n",
    "X = np.zeros(shape=(reviews['user_id'].nunique(), reviews['item_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b66889-3914-4661-87c9-4d6bcb04b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in reviews.iterrows():\n",
    "    user_id, item_id, rating = row[USER_KEY], row[ITEM_KEY], row[RATING_KEY]\n",
    "    X[user_id][item_id] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4cbb9-e530-4f74-a040-8e25ff0400be",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52f8871e-2a53-4338-a7db-42c251f91baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = copy.deepcopy(X)\n",
    "valid_X = np.zeros(shape=X.shape)\n",
    "test_X = np.zeros(shape=X.shape)\n",
    "\n",
    "for user_id, reviews in user_to_reviews.items():\n",
    "    # can confirm this actually shuffles properly (this code block works)\n",
    "    random.shuffle(reviews)\n",
    "\n",
    "    # Leave one out for valid\n",
    "    valid_review = reviews[0]\n",
    "    train_X[valid_review.user_id][valid_review.item_id] = 0\n",
    "    valid_X[valid_review.user_id][valid_review.item_id] = valid_review.rating\n",
    "    \n",
    "    # Leave one out for test\n",
    "    test_review = reviews[1]\n",
    "    train_X[test_review.user_id][test_review.item_id] = 0\n",
    "    test_X[test_review.user_id][test_review.item_id] = test_review.rating\n",
    "    \n",
    "    # Rest for train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafc5daa-0f72-4c5e-968a-b1adea2a7a3d",
   "metadata": {},
   "source": [
    "## Creating bias terms for users / items from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7e4f205-bd38-41b7-8bc0-d315ff486b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# users\n",
    "user_to_pos_sent = defaultdict(list)\n",
    "user_to_neg_sent = defaultdict(list)\n",
    "user_to_compound_sent = defaultdict(list)\n",
    "\n",
    "# items\n",
    "item_to_pos_sent = defaultdict(list)\n",
    "item_to_neg_sent = defaultdict(list)\n",
    "item_to_compound_sent = defaultdict(list)\n",
    "\n",
    "# loadding\n",
    "for user_id, reviews in user_to_reviews.items():\n",
    "    for r in reviews:\n",
    "        # skip if not in train\n",
    "        if train_X[user_id, r.item_id] == 0:\n",
    "            continue\n",
    "        user_to_pos_sent[user_id].append(r.pos_sent)\n",
    "        user_to_neg_sent[user_id].append(r.neg_sent)\n",
    "        user_to_compound_sent[user_id].append(r.compound_sent)\n",
    "        item_to_pos_sent[r.item_id].append(r.pos_sent)\n",
    "        item_to_neg_sent[r.item_id].append(r.neg_sent)\n",
    "        item_to_compound_sent[r.item_id].append(r.compound_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d030b3d-53be-433c-a5ff-3e0c774d3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging values to get bias term\n",
    "def list_mapping_to_float_mapping(hm: dict):\n",
    "    id_to_sent_term = defaultdict(float)\n",
    "    for k, v in hm.items():\n",
    "        id_to_sent_term[k] = np.mean(v)\n",
    "    return id_to_sent_term\n",
    "\n",
    "user_to_pos_sent_term = list_mapping_to_float_mapping(user_to_pos_sent)\n",
    "user_to_neg_sent_term = list_mapping_to_float_mapping(user_to_neg_sent)\n",
    "user_to_compound_sent_term = list_mapping_to_float_mapping(user_to_compound_sent)\n",
    "item_to_pos_sent_term = list_mapping_to_float_mapping(item_to_pos_sent)\n",
    "item_to_neg_sent_term = list_mapping_to_float_mapping(item_to_neg_sent)\n",
    "item_to_compound_sent_term = list_mapping_to_float_mapping(item_to_compound_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39d1ea0-2053-4428-b586-df8fca47c966",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Actual NCF (w/ Separate GMF and MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b075113-a9f4-4ee3-9d09-743659ddc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(values):\n",
    "    return torch.sum(torch.square(values))\n",
    "\n",
    " \n",
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=20, regularization_constant=1e-6, sentiment_regularization_constant=1e-6, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_factors = nn.Embedding(num_items, embedding_dim)\n",
    "        self.regularization_constant = regularization_constant\n",
    "        self.sentiment_regularization_constant = sentiment_regularization_constant # unused\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor):\n",
    "        # (users, emb_dim) * (items, emb_dim) = (interactions, emb_dim)\n",
    "        result_tensor = self.user_factors(users) * self.item_factors(items)\n",
    "        user_latent_factors = self.user_factors(users)\n",
    "        item_latent_factors = self.item_factors(items)\n",
    "        pred_ratings = user_latent_factors @ item_latent_factors.T\n",
    "        pred_ratings = 1 + 9 * torch.sigmoid(pred_ratings)\n",
    "        return pred_ratings.diagonal()\n",
    "    \n",
    "    def loss(self, pred_rating: torch.LongTensor, rating: torch.LongTensor, rmse=False):\n",
    "        if rmse:\n",
    "            loss = torch.sqrt(F.mse_loss(pred_rating, rating) + self.eps)\n",
    "        else:\n",
    "            loss = F.mse_loss(pred_rating, rating) + self.eps\n",
    "        \n",
    "        # L2 Regularization\n",
    "        sum_of_squared_values = l2_regularization(self.user_factors.weight) + l2_regularization(self.item_factors.weight)\n",
    "        l2_penalty = (1/len(rating)) * self.regularization_constant * sum_of_squared_values\n",
    "\n",
    "        # Total Loss\n",
    "        total_loss = loss + l2_penalty\n",
    "        return total_loss\n",
    "    \n",
    "    def predict_single_interaction(self, user_id: int, item_id: int):\n",
    "        user = torch.LongTensor([user_id]).cuda()\n",
    "        item = torch.LongTensor([item_id]).cuda()\n",
    "        return self.forward(user, item)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=20, regularization_constant=1e-6, sentiment_regularization_constant=1e-6, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_factors = nn.Embedding(num_items, embedding_dim)\n",
    "        self.regularization_constant = regularization_constant\n",
    "        self.sentiment_regularization_constant = sentiment_regularization_constant # unused\n",
    "        self.eps = eps\n",
    "        \n",
    "        # MLP layers\n",
    "        self.fc1 = nn.Linear(2*embedding_dim, 128)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor):\n",
    "        # user is shape (users, 1)\n",
    "        # item is shape (items, 1)\n",
    "        # embedding output shape is (*, emb_dim) = (users/items, emb_dim)\n",
    "        user_latent_factors = self.user_factors(users)\n",
    "        item_latent_factors = self.item_factors(items)\n",
    "        \n",
    "        # Concat latent facts together => (*, 2*emb_dim)\n",
    "        user_item_latent_factors = torch.cat((user_latent_factors, item_latent_factors), dim=1)\n",
    "\n",
    "        # FC takes (*, in_dim) and outputs (*, out_dim)\n",
    "        output = self.fc1(user_item_latent_factors)\n",
    "        output = self.relu1(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.fc3(output)\n",
    "        \n",
    "        # Clip in the desired range\n",
    "        pred_ratings = 1 + 9 * torch.sigmoid(output).squeeze()  \n",
    "\n",
    "        return pred_ratings\n",
    "    \n",
    "    def loss(self, pred_rating: torch.LongTensor, rating: torch.LongTensor, rmse=False):\n",
    "        if rmse:\n",
    "            loss = torch.sqrt(F.mse_loss(pred_rating, rating) + self.eps)\n",
    "        else:\n",
    "            loss = F.mse_loss(pred_rating, rating) + self.eps\n",
    "        \n",
    "        \n",
    "        # L2 Regularization\n",
    "        sum_of_squared_values = l2_regularization(self.user_factors.weight) + l2_regularization(self.item_factors.weight)\n",
    "        l2_penalty = (1/len(rating)) * self.regularization_constant * sum_of_squared_values\n",
    "        \n",
    "        # Total Loss\n",
    "        total_loss = loss + l2_penalty\n",
    "        return total_loss\n",
    "    \n",
    "    def predict_single_interaction(self, user_id: int, item_id: int):\n",
    "        user = torch.LongTensor([user_id]).cuda()\n",
    "        item = torch.LongTensor([item_id]).cuda()\n",
    "        return self.forward(user, item)\n",
    "\n",
    "    \n",
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, MF_embedding_dim=20, MLP_embedding_dim=20, regularization_constant=1e-6, sentiment_regularization_constant=1e-6, eps=1e-8):\n",
    "        super().__init__()\n",
    "        # User factors\n",
    "        self.MF_user_factors = nn.Embedding(num_users, MF_embedding_dim)\n",
    "        self.MLP_user_factors = nn.Embedding(num_users, MLP_embedding_dim)\n",
    "        \n",
    "        # Item Factors\n",
    "        self.MF_item_factors = nn.Embedding(num_users, MF_embedding_dim)\n",
    "        self.MLP_item_factors = nn.Embedding(num_users, MLP_embedding_dim)\n",
    "\n",
    "        \n",
    "        # GMF Layer\n",
    "        # element wise product\n",
    "        \n",
    "        # MLP Layers\n",
    "        self.fc1 = nn.Linear(2*embedding_dim, 128)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "        # Trainable NeuMF Layer (in the original paper it's just a hyperparameter)\n",
    "        # Initialize to [0.5, 0.5]\n",
    "        self.neumf_layer = nn.Linear(2, 1)\n",
    "        self.neumf_layer.weight.data = torch.Tensor([[0.5, 0.5]]).to(device)\n",
    "        \n",
    "        ## The usual constants\n",
    "        self.regularization_constant = regularization_constant\n",
    "        self.sentiment_regularization_constant = sentiment_regularization_constant # unused\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor):\n",
    "        # There are all (users x emb_dim), as usual\n",
    "        MF_latent_user_factors = self.MF_user_factors(users)\n",
    "        MLP_latent_user_factors = self.MLP_user_factors(users)\n",
    "        \n",
    "        MLP_latent_item_factors = self.MLP_item_factors(items)\n",
    "        MF_latent_item_factors = self.MF_item_factors(items)\n",
    "        \n",
    "        # GMF Layer\n",
    "        gmf_output = (MF_latent_user_factors @ MF_latent_item_factors.T).diagonal().unsqueeze(1)\n",
    "        \n",
    "        # MLP Layers\n",
    "        concat_latent_factors = torch.cat((MLP_latent_user_factors, MLP_latent_item_factors), dim=1)\n",
    "        mlp_output = self.fc1(concat_latent_factors)\n",
    "        mlp_output = self.relu1(mlp_output)\n",
    "        mlp_output = self.fc2(mlp_output)\n",
    "        mlp_output = self.relu2(mlp_output)\n",
    "        mlp_output = self.fc3(mlp_output)\n",
    "        \n",
    "        # NeuMF Layer\n",
    "        combined_output = torch.cat((gmf_output, mlp_output), dim=1)\n",
    "        pred_ratings = self.neumf_layer(combined_output).squeeze()\n",
    "        pred_ratings = 1 + 9 * torch.sigmoid(pred_ratings)\n",
    "        \n",
    "        return pred_ratings\n",
    "    \n",
    "    def loss(self, pred_rating: torch.LongTensor, rating: torch.LongTensor, rmse=False):\n",
    "        if rmse:\n",
    "            loss = torch.sqrt(F.mse_loss(pred_rating, rating) + self.eps)\n",
    "        else:\n",
    "            loss = F.mse_loss(pred_rating, rating) + self.eps\n",
    "        \n",
    "        # L2 Regularization\n",
    "        sum_of_squared_values = l2_regularization(self.MF_user_factors.weight) + l2_regularization(self.MF_item_factors.weight)\n",
    "        sum_of_squared_values += l2_regularization(self.MLP_user_factors.weight)\n",
    "        sum_of_squared_values += l2_regularization(self.MLP_item_factors.weight)\n",
    "        for f in [self.fc1, self.fc2, self.fc3]:\n",
    "            sum_of_squared_values += l2_regularization(f.weight)\n",
    "        l2_penalty = (1/len(rating)) * self.regularization_constant * sum_of_squared_values\n",
    "\n",
    "        # Total Loss\n",
    "        total_loss = loss + l2_penalty\n",
    "        return total_loss\n",
    "    \n",
    "    def predict_single_interaction(self, user_id: int, item_id: int):\n",
    "        user = torch.LongTensor([user_id]).cuda()\n",
    "        item = torch.LongTensor([item_id]).cuda()\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ccfc7c5-88ec-47ad-aced-9f57b6e60bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_MSE_loss(eval_X, model, round_digits=3):\n",
    "    \"\"\"Uses reduction mean\"\"\"\n",
    "    user_ids_list, item_ids_list = eval_X.nonzero()\n",
    "    gt_ratings = torch.FloatTensor([eval_X[user_id, item_id] for user_id, item_id in zip(user_ids_list, item_ids_list)]).to(device)\n",
    "    curr_users_tensor = torch.LongTensor(user_ids_list).to(device)\n",
    "    curr_items_tensor = torch.LongTensor(item_ids_list).to(device)\n",
    "    pred_ratings = model.forward(curr_users_tensor, curr_items_tensor)\n",
    "    \n",
    "    return round(F.mse_loss(pred_ratings, gt_ratings).item(), 3)\n",
    "\n",
    "def eval_RMSE_loss(eval_X, model):\n",
    "    \"\"\"Uses reduction mean\"\"\"\n",
    "    user_ids_list, item_ids_list = eval_X.nonzero()\n",
    "    gt_ratings = torch.FloatTensor([eval_X[user_id, item_id] for user_id, item_id in zip(user_ids_list, item_ids_list)]).to(device)\n",
    "    curr_users_tensor = torch.LongTensor(user_ids_list).to(device)\n",
    "    curr_items_tensor = torch.LongTensor(item_ids_list).to(device)\n",
    "    pred_ratings = model.forward(curr_users_tensor, curr_items_tensor)\n",
    "    \n",
    "    return round(torch.sqrt(F.mse_loss(pred_ratings, gt_ratings)).item(), 3)\n",
    "\n",
    "def eval_MAE_loss(eval_X, model):\n",
    "    \"\"\"Uses reduction mean\"\"\"\n",
    "    user_ids_list, item_ids_list = eval_X.nonzero()\n",
    "    gt_ratings = torch.FloatTensor([eval_X[user_id, item_id] for user_id, item_id in zip(user_ids_list, item_ids_list)]).to(device)\n",
    "    curr_users_tensor = torch.LongTensor(user_ids_list).to(device)\n",
    "    curr_items_tensor = torch.LongTensor(item_ids_list).to(device)\n",
    "    pred_ratings = model.forward(curr_users_tensor, curr_items_tensor)\n",
    "    \n",
    "    return round(F.l1_loss(pred_ratings, gt_ratings).item(), 3)\n",
    "\n",
    "\n",
    "def train_v2(train_X, valid_X, model, optimizer, n_epochs=10, batch_size=5, rmse=False):\n",
    "    \"\"\"Training Function, calculates training and validation loss\"\"\"\n",
    "    \n",
    "    for epoch in (range(1, n_epochs+1)):\n",
    "        users, items = train_X.nonzero()\n",
    "        num_examples = len(users)\n",
    "        permuted_indices = np.random.permutation(num_examples)\n",
    "        users, items = users[permuted_indices], items[permuted_indices]\n",
    "        \n",
    "\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        \n",
    "        for i in tqdm(range(num_examples // batch_size)):\n",
    "            user_ids_list = users[i*batch_size:i*batch_size+batch_size]\n",
    "            item_ids_list = items[i*batch_size:i*batch_size+batch_size]\n",
    "\n",
    "            # Set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Turn data into tensors\n",
    "            ratings = torch.FloatTensor([train_X[user_id, item_id] for user_id, item_id in zip(user_ids_list, item_ids_list)]).to(device)\n",
    "            curr_users_tensor = torch.LongTensor(user_ids_list).to(device)\n",
    "            curr_items_tensor = torch.LongTensor(item_ids_list).to(device)\n",
    "\n",
    "            # Predict and calculate loss\n",
    "            pred_ratings = model.forward(curr_users_tensor, curr_items_tensor)\n",
    "            assert pred_ratings.shape == ratings.shape\n",
    "            \n",
    "            ## SELECTING LOSS HERE\n",
    "            # loss = model.loss(pred_rating, rating)\n",
    "            loss = model.loss(pred_ratings, ratings, rmse=rmse)\n",
    "\n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # MSE Loss w/o regularization (just for status updates)\n",
    "            total_train_loss += F.mse_loss(pred_ratings, ratings, reduction='sum')\n",
    "\n",
    "        # Computing validation loss for display\n",
    "        total_valid_loss = eval_MSE_loss(valid_X, model)\n",
    "        total_valid_RMSE_loss = eval_RMSE_loss(valid_X, model)\n",
    "        total_valid_MAE_loss = eval_MAE_loss(valid_X, model)\n",
    "        \n",
    "        print(f\"Epoch {epoch} MSE Loss: {round(total_train_loss.item() / (batch_size * (num_examples//batch_size)), 3)}, valid MSE Loss: {total_valid_loss}, valid RMSE Loss: {total_valid_RMSE_loss}, valid MAE Loss: {total_valid_MAE_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68147f34-7dda-4d23-8269-ad1997f26640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(test_X, model):\n",
    "    total_test_loss = eval_MSE_loss(test_X, model)\n",
    "    total_test_RMSE_loss = eval_RMSE_loss(test_X, model)\n",
    "    total_test_MAE_loss = eval_MAE_loss(test_X, model)\n",
    "    print(f\"test MSE Loss: {total_test_loss}, test RMSE Loss: {total_test_RMSE_loss}, test MAE Loss: {total_test_MAE_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f53fe5-9de6-4808-832b-c4bc365c9686",
   "metadata": {},
   "source": [
    "## Config Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50ba0265-0529-4485-9e20-29faf8bb9391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May  3 04:59:53 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   66C    P0   294W / 300W |  32444MiB / 32510MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    87W / 300W |  23318MiB / 32510MiB |     10%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   47C    P0    90W / 300W |  15317MiB / 32510MiB |     45%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   59C    P0   295W / 300W |  32436MiB / 32510MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   65C    P0   293W / 300W |  32444MiB / 32510MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    58W / 300W |  17105MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    58W / 300W |  17689MiB / 32510MiB |     23%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    56W / 300W |  18922MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   2915695      C   python                          32441MiB |\n",
      "|    1   N/A  N/A   1451706      C   python3                         23315MiB |\n",
      "|    2   N/A  N/A    494696      C   ...he46/anaconda3/bin/python    10219MiB |\n",
      "|    2   N/A  N/A   2124058      C   python3                          2357MiB |\n",
      "|    2   N/A  N/A   2465534      C   python3                          1133MiB |\n",
      "|    2   N/A  N/A   3142449      C   python                           1603MiB |\n",
      "|    3   N/A  N/A    916265      C   python                          32433MiB |\n",
      "|    4   N/A  N/A   2310855      C   python                          32441MiB |\n",
      "|    5   N/A  N/A    165739      C   ...he46/anaconda3/bin/python     4189MiB |\n",
      "|    5   N/A  N/A    515640      C   ...he46/anaconda3/bin/python     6125MiB |\n",
      "|    5   N/A  N/A   1627863      C   ...he46/anaconda3/bin/python     5109MiB |\n",
      "|    5   N/A  N/A   1905922      C   ...onda3/envs/nlp/bin/python     1675MiB |\n",
      "|    6   N/A  N/A    201466      C   ...he46/anaconda3/bin/python     1317MiB |\n",
      "|    6   N/A  N/A   1627863      C   ...he46/anaconda3/bin/python     4939MiB |\n",
      "|    6   N/A  N/A   2289016      C   python3                          1657MiB |\n",
      "|    6   N/A  N/A   3907318      C   ...he46/anaconda3/bin/python     9771MiB |\n",
      "|    7   N/A  N/A   2610518      C   ...he46/anaconda3/bin/python     4295MiB |\n",
      "|    7   N/A  N/A   3203151      C   ...he46/anaconda3/bin/python    14071MiB |\n",
      "|    7   N/A  N/A   3907318      C   ...he46/anaconda3/bin/python      551MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d5a0326-0258-4111-84b7-a978f80e8bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], device='cuda:5')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Forcing GPU\n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(\"cuda:5\")\n",
    "device = torch.device(\"cuda\")\n",
    "a = torch.tensor([[1., 2.], [3., 4.]]).to(device)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e0d79-d054-4bef-889e-7f88187c0ba2",
   "metadata": {},
   "source": [
    "## Training GMF and MLP Independently\n",
    "As per the NCF paper, we must train GMF and MLP separately. Then, we initialize NeuMF using the pretrained models of GMF and MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12498052-3871-4d4b-9b35-3ad7ac943a15",
   "metadata": {},
   "source": [
    "### Training GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96bac942-b9c7-43ea-ac27-ba22eadac32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.9524], device='cuda:5', grad_fn=<DiagonalBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Params\n",
    "embedding_dim=200\n",
    "lr=.01\n",
    "regularization_constant=.01\n",
    "\n",
    "# Test\n",
    "gmf = GMF(num_users=X.shape[0], num_items=X.shape[1], embedding_dim=embedding_dim, regularization_constant=regularization_constant)\n",
    "optimizer = torch.optim.Adam(gmf.parameters(), lr=lr)\n",
    "gmf.to(device)\n",
    "gmf.predict_single_interaction(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1c014b0-1ef5-4d91-beda-38eb31d34c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 355.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 MSE Loss: 15.632, valid MSE Loss: 8.869, valid RMSE Loss: 2.978, valid MAE Loss: 2.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 354.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 MSE Loss: 4.077, valid MSE Loss: 4.958, valid RMSE Loss: 2.227, valid MAE Loss: 1.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 285.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 MSE Loss: 2.379, valid MSE Loss: 4.184, valid RMSE Loss: 2.045, valid MAE Loss: 1.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 445.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 MSE Loss: 2.195, valid MSE Loss: 4.014, valid RMSE Loss: 2.004, valid MAE Loss: 1.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 396.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 MSE Loss: 2.307, valid MSE Loss: 4.027, valid RMSE Loss: 2.007, valid MAE Loss: 1.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 398.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 MSE Loss: 2.458, valid MSE Loss: 4.032, valid RMSE Loss: 2.008, valid MAE Loss: 1.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 307.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 MSE Loss: 2.537, valid MSE Loss: 4.17, valid RMSE Loss: 2.042, valid MAE Loss: 1.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 395.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 MSE Loss: 2.541, valid MSE Loss: 3.995, valid RMSE Loss: 1.999, valid MAE Loss: 1.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 348.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 MSE Loss: 2.467, valid MSE Loss: 4.03, valid RMSE Loss: 2.008, valid MAE Loss: 1.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 374.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 MSE Loss: 2.363, valid MSE Loss: 3.861, valid RMSE Loss: 1.965, valid MAE Loss: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 324.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 MSE Loss: 2.255, valid MSE Loss: 3.929, valid RMSE Loss: 1.982, valid MAE Loss: 1.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 348.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 MSE Loss: 2.15, valid MSE Loss: 3.749, valid RMSE Loss: 1.936, valid MAE Loss: 1.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 304.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 MSE Loss: 2.047, valid MSE Loss: 3.809, valid RMSE Loss: 1.952, valid MAE Loss: 1.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 325.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 MSE Loss: 1.963, valid MSE Loss: 3.739, valid RMSE Loss: 1.934, valid MAE Loss: 1.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 317.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 MSE Loss: 1.923, valid MSE Loss: 3.679, valid RMSE Loss: 1.918, valid MAE Loss: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 333.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 MSE Loss: 1.845, valid MSE Loss: 3.682, valid RMSE Loss: 1.919, valid MAE Loss: 1.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 377.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 MSE Loss: 1.793, valid MSE Loss: 3.688, valid RMSE Loss: 1.92, valid MAE Loss: 1.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 335.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 MSE Loss: 1.733, valid MSE Loss: 3.737, valid RMSE Loss: 1.933, valid MAE Loss: 1.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 300.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 MSE Loss: 1.708, valid MSE Loss: 3.669, valid RMSE Loss: 1.915, valid MAE Loss: 1.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 316.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 MSE Loss: 1.681, valid MSE Loss: 3.647, valid RMSE Loss: 1.91, valid MAE Loss: 1.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 372.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 MSE Loss: 1.642, valid MSE Loss: 3.65, valid RMSE Loss: 1.91, valid MAE Loss: 1.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 352.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 MSE Loss: 1.625, valid MSE Loss: 3.635, valid RMSE Loss: 1.907, valid MAE Loss: 1.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 349.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 MSE Loss: 1.623, valid MSE Loss: 3.661, valid RMSE Loss: 1.913, valid MAE Loss: 1.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 450.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 MSE Loss: 1.614, valid MSE Loss: 3.625, valid RMSE Loss: 1.904, valid MAE Loss: 1.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 366.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 MSE Loss: 1.581, valid MSE Loss: 3.702, valid RMSE Loss: 1.924, valid MAE Loss: 1.532\n"
     ]
    }
   ],
   "source": [
    "train_v2(train_X, valid_X, gmf, optimizer, n_epochs=25, batch_size=64, rmse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c4773fe-da72-45e3-8098-4506195b0337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE Loss: 3.83, test RMSE Loss: 1.957, test MAE Loss: 1.562\n"
     ]
    }
   ],
   "source": [
    "eval_model(test_X, gmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706de2c8-30ee-4766-ad24-636feb6adbe2",
   "metadata": {},
   "source": [
    "## Training MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07294869-0c4d-4e51-9b43-a77fc80497b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2639, device='cuda:5', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim=200\n",
    "lr=1e-2\n",
    "regularization_constant=.011\n",
    "\n",
    "mlp = MLP(num_users=X.shape[0], num_items=X.shape[1], \n",
    "                    embedding_dim=embedding_dim, \n",
    "                    regularization_constant=regularization_constant,\n",
    "                )\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=lr)\n",
    "mlp.to(device)\n",
    "mlp.predict_single_interaction(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d317ab48-a4fe-4cfa-b31e-dcfb2039aa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 225.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 MSE Loss: 3.856, valid MSE Loss: 3.522, valid RMSE Loss: 1.877, valid MAE Loss: 1.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 195.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 MSE Loss: 3.239, valid MSE Loss: 3.286, valid RMSE Loss: 1.813, valid MAE Loss: 1.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 204.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 MSE Loss: 2.951, valid MSE Loss: 3.107, valid RMSE Loss: 1.763, valid MAE Loss: 1.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 225.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 MSE Loss: 2.808, valid MSE Loss: 3.024, valid RMSE Loss: 1.739, valid MAE Loss: 1.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 207.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 MSE Loss: 2.691, valid MSE Loss: 3.058, valid RMSE Loss: 1.749, valid MAE Loss: 1.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 194.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 MSE Loss: 2.651, valid MSE Loss: 2.938, valid RMSE Loss: 1.714, valid MAE Loss: 1.291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 192.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 MSE Loss: 2.591, valid MSE Loss: 2.947, valid RMSE Loss: 1.717, valid MAE Loss: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 187.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 MSE Loss: 2.549, valid MSE Loss: 2.996, valid RMSE Loss: 1.731, valid MAE Loss: 1.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 217.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 MSE Loss: 2.572, valid MSE Loss: 3.016, valid RMSE Loss: 1.737, valid MAE Loss: 1.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 197.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 MSE Loss: 2.514, valid MSE Loss: 2.901, valid RMSE Loss: 1.703, valid MAE Loss: 1.287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 193.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 MSE Loss: 2.476, valid MSE Loss: 3.009, valid RMSE Loss: 1.735, valid MAE Loss: 1.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 232.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 MSE Loss: 2.488, valid MSE Loss: 2.923, valid RMSE Loss: 1.71, valid MAE Loss: 1.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 231.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 MSE Loss: 2.461, valid MSE Loss: 2.89, valid RMSE Loss: 1.7, valid MAE Loss: 1.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 218.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 MSE Loss: 2.437, valid MSE Loss: 2.919, valid RMSE Loss: 1.708, valid MAE Loss: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 197.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 MSE Loss: 2.429, valid MSE Loss: 3.0, valid RMSE Loss: 1.732, valid MAE Loss: 1.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 189.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 MSE Loss: 2.406, valid MSE Loss: 3.015, valid RMSE Loss: 1.736, valid MAE Loss: 1.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 196.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 MSE Loss: 2.393, valid MSE Loss: 2.921, valid RMSE Loss: 1.709, valid MAE Loss: 1.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 206.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 MSE Loss: 2.368, valid MSE Loss: 3.016, valid RMSE Loss: 1.737, valid MAE Loss: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 192.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 MSE Loss: 2.365, valid MSE Loss: 2.931, valid RMSE Loss: 1.712, valid MAE Loss: 1.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 216.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 MSE Loss: 2.344, valid MSE Loss: 2.985, valid RMSE Loss: 1.728, valid MAE Loss: 1.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 197.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 MSE Loss: 2.325, valid MSE Loss: 2.962, valid RMSE Loss: 1.721, valid MAE Loss: 1.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 210.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 MSE Loss: 2.315, valid MSE Loss: 3.02, valid RMSE Loss: 1.738, valid MAE Loss: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 200.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 MSE Loss: 2.314, valid MSE Loss: 3.08, valid RMSE Loss: 1.755, valid MAE Loss: 1.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 190.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 MSE Loss: 2.272, valid MSE Loss: 3.127, valid RMSE Loss: 1.768, valid MAE Loss: 1.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:01<00:00, 256.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 MSE Loss: 2.272, valid MSE Loss: 2.98, valid RMSE Loss: 1.726, valid MAE Loss: 1.287\n"
     ]
    }
   ],
   "source": [
    "train_v2(train_X, valid_X, mlp, optimizer, n_epochs=25, batch_size=64, rmse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00abe88c-6219-4add-b889-ded0d444f961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE Loss: 3.196, test RMSE Loss: 1.788, test MAE Loss: 1.335\n"
     ]
    }
   ],
   "source": [
    "eval_model(test_X, mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e0e20-2eb2-47cb-b523-8fd9e12bc9ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the combined model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c96ba-8163-47a6-8b80-445c5e2cf90d",
   "metadata": {},
   "source": [
    "### Hyper Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48722b36-3e75-4f86-bbc0-fb7cb6a3c087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0486, device='cuda:5', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF_embedding_dim=200\n",
    "MLP_embedding_dim=200\n",
    "lr=1e-2\n",
    "regularization_constant=1e-2\n",
    "\n",
    "neumf = NeuMF(num_users=X.shape[0], num_items=X.shape[1], \n",
    "                    MF_embedding_dim=MF_embedding_dim, \n",
    "                    MLP_embedding_dim=MLP_embedding_dim,\n",
    "                    regularization_constant=regularization_constant,\n",
    "                )\n",
    "\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=lr)\n",
    "neumf.to(device)\n",
    "neumf.predict_single_interaction(0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a656c07-b5bb-4846-88b3-5b6c4c773be3",
   "metadata": {},
   "source": [
    "### Assign the pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01b5fbad-5a7f-4189-ad18-7b329cf6b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pretrained(NeuMF_model, GMF_model, MLP_model):\n",
    "    # Latent weights\n",
    "    NeuMF_model.MF_user_factors.weight = GMF_model.user_factors.weight\n",
    "    NeuMF_model.MF_item_factors.weight = GMF_model.item_factors.weight\n",
    "    NeuMF_model.MLP_user_factors.weight = MLP_model.user_factors.weight\n",
    "    NeuMF_model.MLP_item_factors.weight = MLP_model.item_factors.weight\n",
    "    \n",
    "    # MLP weights\n",
    "    NeuMF_model.fc1.weight = MLP_model.fc1.weight\n",
    "    NeuMF_model.fc2.weight = MLP_model.fc2.weight\n",
    "    NeuMF_model.fc3.weight = MLP_model.fc3.weight\n",
    "    \n",
    "init_pretrained(neumf, gmf, mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e4dc24-e255-4f47-a153-ec01b2856be3",
   "metadata": {},
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45594946-1156-49a7-8b16-c44c500b5bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 184.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 MSE Loss: 0.997, valid MSE Loss: 3.125, valid RMSE Loss: 1.768, valid MAE Loss: 1.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 182.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 MSE Loss: 0.989, valid MSE Loss: 3.137, valid RMSE Loss: 1.771, valid MAE Loss: 1.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 189.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 MSE Loss: 0.985, valid MSE Loss: 3.138, valid RMSE Loss: 1.772, valid MAE Loss: 1.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 182.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 MSE Loss: 0.979, valid MSE Loss: 3.14, valid RMSE Loss: 1.772, valid MAE Loss: 1.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 191.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 MSE Loss: 0.973, valid MSE Loss: 3.117, valid RMSE Loss: 1.766, valid MAE Loss: 1.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 185.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 MSE Loss: 0.967, valid MSE Loss: 3.126, valid RMSE Loss: 1.768, valid MAE Loss: 1.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 181.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 MSE Loss: 0.962, valid MSE Loss: 3.119, valid RMSE Loss: 1.766, valid MAE Loss: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 177.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 MSE Loss: 0.956, valid MSE Loss: 3.128, valid RMSE Loss: 1.769, valid MAE Loss: 1.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 204.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 MSE Loss: 0.951, valid MSE Loss: 3.126, valid RMSE Loss: 1.768, valid MAE Loss: 1.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 206.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 MSE Loss: 0.946, valid MSE Loss: 3.097, valid RMSE Loss: 1.76, valid MAE Loss: 1.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 208.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 MSE Loss: 0.941, valid MSE Loss: 3.12, valid RMSE Loss: 1.766, valid MAE Loss: 1.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 206.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 MSE Loss: 0.936, valid MSE Loss: 3.102, valid RMSE Loss: 1.761, valid MAE Loss: 1.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 191.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 MSE Loss: 0.931, valid MSE Loss: 3.11, valid RMSE Loss: 1.764, valid MAE Loss: 1.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 187.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 MSE Loss: 0.926, valid MSE Loss: 3.108, valid RMSE Loss: 1.763, valid MAE Loss: 1.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 198.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 MSE Loss: 0.921, valid MSE Loss: 3.137, valid RMSE Loss: 1.771, valid MAE Loss: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 187.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 MSE Loss: 0.917, valid MSE Loss: 3.106, valid RMSE Loss: 1.762, valid MAE Loss: 1.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:03<00:00, 168.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 MSE Loss: 0.912, valid MSE Loss: 3.118, valid RMSE Loss: 1.766, valid MAE Loss: 1.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 183.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 MSE Loss: 0.908, valid MSE Loss: 3.127, valid RMSE Loss: 1.768, valid MAE Loss: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 181.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 MSE Loss: 0.902, valid MSE Loss: 3.128, valid RMSE Loss: 1.769, valid MAE Loss: 1.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 191.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 MSE Loss: 0.898, valid MSE Loss: 3.106, valid RMSE Loss: 1.762, valid MAE Loss: 1.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 199.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 MSE Loss: 0.893, valid MSE Loss: 3.109, valid RMSE Loss: 1.763, valid MAE Loss: 1.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 205.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 MSE Loss: 0.888, valid MSE Loss: 3.134, valid RMSE Loss: 1.77, valid MAE Loss: 1.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 215.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 MSE Loss: 0.884, valid MSE Loss: 3.11, valid RMSE Loss: 1.764, valid MAE Loss: 1.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 203.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 MSE Loss: 0.879, valid MSE Loss: 3.112, valid RMSE Loss: 1.764, valid MAE Loss: 1.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 508/508 [00:02<00:00, 181.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 MSE Loss: 0.874, valid MSE Loss: 3.112, valid RMSE Loss: 1.764, valid MAE Loss: 1.321\n"
     ]
    }
   ],
   "source": [
    "train_v2(train_X, valid_X, neumf, optimizer, n_epochs=25, batch_size=64, rmse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88634e08-b868-4c34-b0dd-66762819ea5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "273f1066-9813-4096-b953-2155f3b4ea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE Loss: 3.323, test RMSE Loss: 1.823, test MAE Loss: 1.376\n"
     ]
    }
   ],
   "source": [
    "total_test_loss = eval_MSE_loss(test_X, neumf)\n",
    "total_test_RMSE_loss = eval_RMSE_loss(test_X, neumf)\n",
    "total_test_MAE_loss = eval_MAE_loss(test_X, neumf)\n",
    "print(f\"test MSE Loss: {total_test_loss}, test RMSE Loss: {total_test_RMSE_loss}, test MAE Loss: {total_test_MAE_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089982d5-b350-4beb-b053-6a5184d2e119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
